{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 4: Procrustes Alignment\n",
                "\n",
                "## Goal\n",
                "Align hieroglyphic and English embedding spaces using Orthogonal Procrustes.\n",
                "This is the same technique that made V3 successful (22% accuracy).\n",
                "\n",
                "## Strategy\n",
                "1. Load hieroglyphic embeddings (FastText trained on 104k texts)\n",
                "2. Load English embeddings (GloVe 300d)\n",
                "3. Extract anchor vectors from both spaces\n",
                "4. Compute Procrustes transformation matrix\n",
                "5. Align hieroglyphic space to English space\n",
                "6. Evaluate and discover new meanings!\n",
                "\n",
                "## Mathematical Background\n",
                "Orthogonal Procrustes finds the optimal rotation matrix **R** that minimizes:\n",
                "```\n",
                "||X·R - Y||²\n",
                "```\n",
                "Where:\n",
                "- X = hieroglyphic anchor vectors\n",
                "- Y = English anchor vectors\n",
                "- R = rotation matrix (computed via SVD)\n",
                "\n",
                "Once we have R, we can map any hieroglyphic word to English space!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Libraries loaded\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pickle\n",
                "import json\n",
                "from pathlib import Path\n",
                "from gensim.models import KeyedVectors\n",
                "from scipy.linalg import orthogonal_procrustes\n",
                "from collections import Counter\n",
                "import pandas as pd\n",
                "\n",
                "print(\"✓ Libraries loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading hieroglyphic embeddings...\n",
                        "✓ Loaded 11,974 hieroglyphic vectors\n",
                        "\n",
                        "Loading GloVe embeddings...\n",
                        "✓ Loaded 400,000 English vectors\n",
                        "\n",
                        "Vector dimensions: 300d (hier) x 300d (eng)\n"
                    ]
                }
            ],
            "source": [
                "# Load hieroglyphic embeddings\n",
                "print(\"Loading hieroglyphic embeddings...\")\n",
                "hier_path = Path('../data/processed/hieroglyphic_vectors.kv')\n",
                "hier_wv = KeyedVectors.load(str(hier_path), mmap='r')\n",
                "print(f\"✓ Loaded {len(hier_wv):,} hieroglyphic vectors\")\n",
                "\n",
                "# Load GloVe English embeddings\n",
                "print(\"\\nLoading GloVe embeddings...\")\n",
                "glove_path = Path('../data/processed/glove.6B.300d.txt')\n",
                "\n",
                "# GloVe format: word vec1 vec2 ... vec300\n",
                "eng_vectors = {}\n",
                "with open(glove_path, 'r', encoding='utf-8') as f:\n",
                "    for line in f:\n",
                "        parts = line.strip().split()\n",
                "        word = parts[0]\n",
                "        vector = np.array([float(x) for x in parts[1:]])\n",
                "        eng_vectors[word] = vector\n",
                "\n",
                "print(f\"✓ Loaded {len(eng_vectors):,} English vectors\")\n",
                "print(f\"\\nVector dimensions: {hier_wv.vector_size}d (hier) x {len(next(iter(eng_vectors.values())))}d (eng)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Anchors and Extract Vectors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 8,541 anchor pairs\n",
                        "\n",
                        "Sample:\n",
                        "  n               → der            \n",
                        "  m               → der            \n",
                        "  =f              → er             \n",
                        "  =k              → du             \n",
                        "  =j              → ich            \n"
                    ]
                }
            ],
            "source": [
                "# Load English anchors\n",
                "anchors_path = Path('../data/processed/english_anchors.pkl')\n",
                "with open(anchors_path, 'rb') as f:\n",
                "    anchors = pickle.load(f)\n",
                "\n",
                "print(f\"Loaded {len(anchors):,} anchor pairs\")\n",
                "print(f\"\\nSample:\")\n",
                "for i in range(5):\n",
                "    a = anchors[i]\n",
                "    print(f\"  {a['hieroglyphic']:15s} → {a['english']:15s}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Valid anchor pairs: 7,471 / 8,541 (87.5%)\n",
                        "\n",
                        "Anchor matrix shapes:\n",
                        "  X (hieroglyphic): (7471, 300)\n",
                        "  Y (English): (7471, 300)\n"
                    ]
                }
            ],
            "source": [
                "# Extract anchor vectors\n",
                "X_list = []  # Hieroglyphic vectors\n",
                "Y_list = []  # English vectors\n",
                "valid_anchors = []\n",
                "\n",
                "for anchor in anchors:\n",
                "    h_word = anchor['hieroglyphic']\n",
                "    e_word = anchor['english']\n",
                "    \n",
                "    # Check if both words exist in embeddings\n",
                "    if h_word in hier_wv and e_word in eng_vectors:\n",
                "        X_list.append(hier_wv[h_word])\n",
                "        Y_list.append(eng_vectors[e_word])\n",
                "        valid_anchors.append(anchor)\n",
                "\n",
                "X = np.array(X_list)\n",
                "Y = np.array(Y_list)\n",
                "\n",
                "print(f\"Valid anchor pairs: {len(valid_anchors):,} / {len(anchors):,} ({len(valid_anchors)/len(anchors)*100:.1f}%)\")\n",
                "print(f\"\\nAnchor matrix shapes:\")\n",
                "print(f\"  X (hieroglyphic): {X.shape}\")\n",
                "print(f\"  Y (English): {Y.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compute Procrustes Transformation\n",
                "\n",
                "Find the optimal rotation matrix R using SVD."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Transformation matrix computed\n",
                        "  Shape: (300, 300)\n",
                        "  Scale factor: 80381.3102\n",
                        "  Orthogonality error: 0.000000\n"
                    ]
                }
            ],
            "source": [
                "# Compute optimal rotation matrix\n",
                "R, scale = orthogonal_procrustes(X, Y)\n",
                "\n",
                "print(f\"✓ Transformation matrix computed\")\n",
                "print(f\"  Shape: {R.shape}\")\n",
                "print(f\"  Scale factor: {scale:.4f}\")\n",
                "\n",
                "# Verify it's orthogonal (R^T · R ≈ I)\n",
                "orthogonality_error = np.linalg.norm(R.T @ R - np.eye(R.shape[0]))\n",
                "print(f\"  Orthogonality error: {orthogonality_error:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Align Hieroglyphic Space\n",
                "\n",
                "Transform all hieroglyphic vectors to English space."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Aligning hieroglyphic vectors...\n",
                        "✓ Aligned 11,974 hieroglyphic vectors to English space\n"
                    ]
                }
            ],
            "source": [
                "# Create aligned hieroglyphic vectors\n",
                "print(\"Aligning hieroglyphic vectors...\")\n",
                "\n",
                "aligned_hier = {}\n",
                "for word in hier_wv.index_to_key:\n",
                "    # Transform: v_aligned = v_hier · R\n",
                "    aligned_hier[word] = hier_wv[word] @ R\n",
                "\n",
                "print(f\"✓ Aligned {len(aligned_hier):,} hieroglyphic vectors to English space\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Translation Function\n",
                "\n",
                "Find the nearest English word for any hieroglyphic word."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Translation function ready\n"
                    ]
                }
            ],
            "source": [
                "def translate_hieroglyphic(h_word, topn=5):\n",
                "    \"\"\"\n",
                "    Translate a hieroglyphic word to English by finding nearest neighbors.\n",
                "    \"\"\"\n",
                "    if h_word not in aligned_hier:\n",
                "        return None\n",
                "    \n",
                "    h_vec = aligned_hier[h_word]\n",
                "    \n",
                "    # Compute cosine similarity with all English words\n",
                "    similarities = {}\n",
                "    for e_word, e_vec in eng_vectors.items():\n",
                "        # Cosine similarity\n",
                "        sim = np.dot(h_vec, e_vec) / (np.linalg.norm(h_vec) * np.linalg.norm(e_vec))\n",
                "        similarities[e_word] = sim\n",
                "    \n",
                "    # Get top N\n",
                "    top = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:topn]\n",
                "    return top\n",
                "\n",
                "print(\"✓ Translation function ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test Translations\n",
                "\n",
                "Let's test on some key words from V3's discoveries!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Translation Tests:\n",
                        "======================================================================\n",
                        "\n",
                        "✓ wsjr            (expected: osiris)\n",
                        "  Top predictions:\n",
                        "    osiris               (score: 0.615)\n",
                        "    der                  (score: 0.404)\n",
                        "    anubis               (score: 0.387)\n",
                        "    isis                 (score: 0.324)\n",
                        "    und                  (score: 0.321)\n",
                        "\n",
                        "✓ ḥr,w            (expected: horus)\n",
                        "  Top predictions:\n",
                        "    horus                (score: 0.621)\n",
                        "    der                  (score: 0.402)\n",
                        "    zum                  (score: 0.346)\n",
                        "    anubis               (score: 0.343)\n",
                        "    deutschen            (score: 0.339)\n",
                        "\n",
                        "✓ ppy             (expected: pepi)\n",
                        "  Top predictions:\n",
                        "    pepi                 (score: 0.671)\n",
                        "    ist                  (score: 0.390)\n",
                        "    gott                 (score: 0.387)\n",
                        "    der                  (score: 0.353)\n",
                        "    auf                  (score: 0.351)\n",
                        "\n",
                        "✓ zꜣ              (expected: son)\n",
                        "  Top predictions:\n",
                        "    son                  (score: 0.474)\n",
                        "    father               (score: 0.444)\n",
                        "    der                  (score: 0.419)\n",
                        "    eldest               (score: 0.407)\n",
                        "    grandfather          (score: 0.388)\n",
                        "\n",
                        "✓ nṯr             (expected: god)\n",
                        "  Top predictions:\n",
                        "    god                  (score: 0.613)\n",
                        "    christ               (score: 0.415)\n",
                        "    scripture            (score: 0.412)\n",
                        "    divine               (score: 0.407)\n",
                        "    bless                (score: 0.407)\n",
                        "\n",
                        "✓ mw              (expected: water)\n",
                        "  Top predictions:\n",
                        "    water                (score: 0.577)\n",
                        "    potable              (score: 0.455)\n",
                        "    irrigation           (score: 0.405)\n",
                        "    groundwater          (score: 0.398)\n",
                        "    seawater             (score: 0.381)\n",
                        "\n",
                        "✗ ꜥnḫ             (expected: life)\n",
                        "  Top predictions:\n",
                        "    live                 (score: 0.474)\n",
                        "    im                   (score: 0.391)\n",
                        "    und                  (score: 0.378)\n",
                        "    der                  (score: 0.349)\n",
                        "    premiered            (score: 0.349)\n",
                        "\n",
                        "✓ rꜥw             (expected: re)\n",
                        "  Top predictions:\n",
                        "    re                   (score: 0.546)\n",
                        "    deutschen            (score: 0.378)\n",
                        "    und                  (score: 0.361)\n",
                        "    der                  (score: 0.333)\n",
                        "    gott                 (score: 0.330)\n"
                    ]
                }
            ],
            "source": [
                "# Test words from V3 and V5\n",
                "test_cases = [\n",
                "    ('wsjr', 'osiris'),      # Osiris (V5 spelling)\n",
                "    ('ḥr,w', 'horus'),       # Horus (V5 spelling)\n",
                "    ('ppy', 'pepi'),         # Pepi\n",
                "    ('zꜣ', 'son'),           # Son\n",
                "    ('nṯr', 'god'),          # God\n",
                "    ('mw', 'water'),         # Water (V3's \"perfect hit\")\n",
                "    ('ꜥnḫ', 'life'),         # Life/living\n",
                "    ('rꜥw', 're'),           # Re (sun god)\n",
                "]\n",
                "\n",
                "print(\"Translation Tests:\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "for h_word, expected in test_cases:\n",
                "    results = translate_hieroglyphic(h_word, topn=5)\n",
                "    \n",
                "    if results:\n",
                "        top_word, top_score = results[0]\n",
                "        match = \"✓\" if top_word.lower() == expected.lower() else \"✗\"\n",
                "        \n",
                "        print(f\"\\n{match} {h_word:15s} (expected: {expected})\")\n",
                "        print(f\"  Top predictions:\")\n",
                "        for word, score in results:\n",
                "            print(f\"    {word:20s} (score: {score:.3f})\")\n",
                "    else:\n",
                "        print(f\"\\n✗ {h_word:15s} - NOT IN VOCABULARY\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate on Anchors\n",
                "\n",
                "Calculate accuracy on our anchor set (like V3's 22%)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m h_word = anchor[\u001b[33m'\u001b[39m\u001b[33mhieroglyphic\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m e_word = anchor[\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results = \u001b[43mtranslate_hieroglyphic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[32m     12\u001b[39m     total += \u001b[32m1\u001b[39m\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtranslate_hieroglyphic\u001b[39m\u001b[34m(h_word, topn)\u001b[39m\n\u001b[32m     11\u001b[39m similarities = {}\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e_word, e_vec \u001b[38;5;129;01min\u001b[39;00m eng_vectors.items():\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Cosine similarity\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     sim = np.dot(h_vec, e_vec) / (\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_vec\u001b[49m\u001b[43m)\u001b[49m * np.linalg.norm(e_vec))\n\u001b[32m     15\u001b[39m     similarities[e_word] = sim\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Get top N\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/numpy/linalg/linalg.py:2546\u001b[39m, in \u001b[36mnorm\u001b[39m\u001b[34m(x, ord, axis, keepdims)\u001b[39m\n\u001b[32m   2541\u001b[39m ndim = x.ndim\n\u001b[32m   2542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   2543\u001b[39m     (\u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfro\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ndim == \u001b[32m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   2544\u001b[39m     (\u001b[38;5;28mord\u001b[39m == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ndim == \u001b[32m1\u001b[39m)):\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m     x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mK\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isComplexType(x.dtype.type):\n\u001b[32m   2548\u001b[39m         x_real = x.real\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "# Evaluate accuracy\n",
                "correct = 0\n",
                "total = 0\n",
                "top5_correct = 0\n",
                "\n",
                "for anchor in valid_anchors:\n",
                "    h_word = anchor['hieroglyphic']\n",
                "    e_word = anchor['english']\n",
                "    \n",
                "    results = translate_hieroglyphic(h_word, topn=5)\n",
                "    if results:\n",
                "        total += 1\n",
                "        top_word = results[0][0]\n",
                "        \n",
                "        if top_word.lower() == e_word.lower():\n",
                "            correct += 1\n",
                "        \n",
                "        # Check if in top 5\n",
                "        if e_word.lower() in [w.lower() for w, _ in results]:\n",
                "            top5_correct += 1\n",
                "\n",
                "accuracy = correct / total * 100 if total > 0 else 0\n",
                "top5_accuracy = top5_correct / total * 100 if total > 0 else 0\n",
                "\n",
                "print(\"Evaluation Results:\")\n",
                "print(\"=\"*70)\n",
                "print(f\"Total anchors evaluated: {total:,}\")\n",
                "print(f\"\\nTop-1 Accuracy: {correct:,} / {total:,} = {accuracy:.2f}%\")\n",
                "print(f\"Top-5 Accuracy: {top5_correct:,} / {total:,} = {top5_accuracy:.2f}%\")\n",
                "print(f\"\\nV3 Baseline: 22% (top-1)\")\n",
                "print(f\"V5 vs V3: {accuracy - 22:+.2f}% improvement\" if accuracy > 22 else f\"V5 vs V3: {accuracy - 22:.2f}% (needs improvement)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Discover New Meanings\n",
                "\n",
                "The exciting part! Let's explore words that might reveal new insights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interesting words to explore\n",
                "discovery_words = [\n",
                "    'inpw',      # Anubis (if in V5 dataset)\n",
                "    'wsjr',      # Osiris\n",
                "    'ḥr,w',      # Horus\n",
                "    'nṯr',       # God\n",
                "    'ḥm-nṯr',    # Priest\n",
                "    'ḥqt',       # Beer\n",
                "    'rꜥw',       # Ra\n",
                "]\n",
                "\n",
                "print(\"New Discoveries:\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "for word in discovery_words:\n",
                "    results = translate_hieroglyphic(word, topn=10)\n",
                "    if results:\n",
                "        print(f\"\\n{word}:\")\n",
                "        for i, (e_word, score) in enumerate(results, 1):\n",
                "            print(f\"  {i:2d}. {e_word:20s} (score: {score:.3f})\")\n",
                "    else:\n",
                "        print(f\"\\n{word}: NOT FOUND\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save transformation matrix\n",
                "np.save('../data/processed/procrustes_matrix.npy', R)\n",
                "print(\"✓ Saved transformation matrix\")\n",
                "\n",
                "# Save evaluation results\n",
                "results = {\n",
                "    'total_anchors': total,\n",
                "    'top1_correct': correct,\n",
                "    'top1_accuracy': accuracy,\n",
                "    'top5_correct': top5_correct,\n",
                "    'top5_accuracy': top5_accuracy,\n",
                "    'v3_baseline': 22.0,\n",
                "    'improvement': accuracy - 22.0\n",
                "}\n",
                "\n",
                "with open('../data/processed/alignment_results.json', 'w') as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(\"✓ Saved evaluation results\")\n",
                "print(f\"\\nFinal V5 Accuracy: {accuracy:.2f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (spontaneous-remission)",
            "language": "python",
            "name": "spontaneous-remission"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
