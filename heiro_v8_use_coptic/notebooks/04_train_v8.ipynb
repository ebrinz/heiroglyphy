{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# V8 Training Pipeline: Retraining Alignment with Enhanced Anchors\n",
        "\n",
        "## Goal\n",
        "Retrain the alignment model using the enhanced anchor dictionary (+368 new anchors from Coptic bridge) and evaluate the improvement in coverage and accuracy.\n",
        "\n",
        "## Process\n",
        "1. **Load Data**: Load enhanced anchors, Egyptian vectors (V7), and English vectors (GloVe).\n",
        "2. **Train Alignment**: Train Ridge Regression to map Egyptian → English.\n",
        "3. **Evaluate**: Measure Top-1, Top-5, and Top-10 accuracy on the test set.\n",
        "4. **Save Results**: Store the final metrics for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from gensim.models import KeyedVectors, FastText\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "\n",
        "We load:\n",
        "- **Enhanced Anchors**: From Phase 2\n",
        "- **Egyptian Vectors**: V7 FastText model (`fasttext_v7.vec`)\n",
        "- **English Vectors**: GloVe 300d (Standard target space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-22 10:52:09,456 - INFO - Loading data...\n",
            "2025-11-22 10:52:09,457 - INFO - Repository Root: /Users/crashy/Development/heiroglyphy\n",
            "2025-11-22 10:52:09,459 - INFO - Loaded 8579 enhanced anchors\n",
            "2025-11-22 10:52:09,460 - INFO - Loading Egyptian model from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model...\n",
            "2025-11-22 10:52:09,460 - INFO - loading FastText object from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model\n",
            "2025-11-22 10:52:09,477 - INFO - loading wv recursively from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model.wv.* with mmap=None\n",
            "2025-11-22 10:52:09,478 - INFO - loading vectors_vocab from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model.wv.vectors_vocab.npy with mmap=None\n",
            "2025-11-22 10:52:09,574 - INFO - loading vectors_ngrams from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model.wv.vectors_ngrams.npy with mmap=None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Root: /Users/crashy/Development/heiroglyphy/heiro_v8_use_coptic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-22 10:52:12,225 - INFO - setting ignored attribute vectors to None\n",
            "2025-11-22 10:52:12,248 - INFO - setting ignored attribute buckets_word to None\n",
            "2025-11-22 10:52:17,186 - INFO - loading syn1neg from /Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model.syn1neg.npy with mmap=None\n",
            "2025-11-22 10:52:17,295 - INFO - setting ignored attribute cum_table to None\n",
            "2025-11-22 10:52:17,597 - INFO - FastText lifecycle event {'fname': '/Users/crashy/Development/heiroglyphy/heiro_v7_FastTextVisual/models/fasttext_v7.model', 'datetime': '2025-11-22T10:52:17.597018', 'gensim': '4.4.0', 'python': '3.12.3 (main, Jun  1 2025, 04:19:33) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-26.1-arm64-arm-64bit', 'event': 'loaded'}\n",
            "2025-11-22 10:52:17,597 - INFO - Loaded model with 80662 vectors\n",
            "2025-11-22 10:52:17,598 - INFO - Loading GloVe vectors from /Users/crashy/Development/heiroglyphy/heiro_v5_getdata/data/processed/glove.6B.300d.txt...\n",
            "2025-11-22 10:52:17,598 - INFO - loading projection weights from /Users/crashy/Development/heiroglyphy/heiro_v5_getdata/data/processed/glove.6B.300d.txt\n",
            "2025-11-22 10:53:27,450 - INFO - KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/crashy/Development/heiroglyphy/heiro_v5_getdata/data/processed/glove.6B.300d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-11-22T10:53:27.450576', 'gensim': '4.4.0', 'python': '3.12.3 (main, Jun  1 2025, 04:19:33) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-26.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
            "2025-11-22 10:53:27,451 - INFO - Loaded 400000 English vectors\n"
          ]
        }
      ],
      "source": [
        "def load_data(project_root):\n",
        "    \"\"\"Load necessary data for training.\"\"\"\n",
        "    logger.info(\"Loading data...\")\n",
        "    \n",
        "    # Define Repository Root (parent of heiro_v8_use_coptic)\n",
        "    repo_root = project_root.parent\n",
        "    logger.info(f\"Repository Root: {repo_root}\")\n",
        "    \n",
        "    # 1. Load Enhanced Anchors (in current project)\n",
        "    anchors_path = project_root / 'data/processed/enhanced_anchors.json'\n",
        "    with open(anchors_path, 'r', encoding='utf-8') as f:\n",
        "        anchors = json.load(f)\n",
        "    logger.info(f\"Loaded {len(anchors)} enhanced anchors\")\n",
        "    \n",
        "    # 2. Load Egyptian Vectors (V7 Model in sibling directory)\n",
        "    egy_model_path = repo_root / 'heiro_v7_FastTextVisual/models/fasttext_v7.model'\n",
        "    logger.info(f\"Loading Egyptian model from {egy_model_path}...\")\n",
        "    \n",
        "    if egy_model_path.exists():\n",
        "        model = FastText.load(str(egy_model_path))\n",
        "        egy_vectors = model.wv\n",
        "        logger.info(f\"Loaded model with {len(egy_vectors)} vectors\")\n",
        "    else:\n",
        "        # Fallback to .vec if model not found\n",
        "        egy_vec_path = repo_root / 'heiro_v7_FastTextVisual/models/fasttext_v7.vec'\n",
        "        logger.warning(f\"Model not found, falling back to vectors at {egy_vec_path}\")\n",
        "        egy_vectors = KeyedVectors.load_word2vec_format(str(egy_vec_path))\n",
        "    \n",
        "    # 3. Load English Vectors (GloVe in sibling directory)\n",
        "    glove_path = repo_root / 'heiro_v5_getdata/data/processed/glove.6B.300d.txt'\n",
        "    logger.info(f\"Loading GloVe vectors from {glove_path}...\")\n",
        "    # GloVe is text format, no header\n",
        "    eng_vectors = KeyedVectors.load_word2vec_format(str(glove_path), binary=False, no_header=True)\n",
        "    logger.info(f\"Loaded {len(eng_vectors)} English vectors\")\n",
        "    \n",
        "    return anchors, egy_vectors, eng_vectors\n",
        "\n",
        "# Set project root\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "print(f\"Project Root: {PROJECT_ROOT}\")\n",
        "\n",
        "anchors, egy_vectors, eng_vectors = load_data(PROJECT_ROOT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Training Data\n",
        "\n",
        "Filter anchors to ensure both words exist in their respective vector spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-22 10:53:30,639 - INFO - Valid Anchors: 7508 / 8579\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(anchors, egy_vectors, eng_vectors):\n",
        "    \"\"\"Prepare X (Egyptian) and Y (English) matrices for alignment.\"\"\"\n",
        "    X = []\n",
        "    Y = []\n",
        "    valid_anchors = []\n",
        "    \n",
        "    for egy_word, eng_word in anchors.items():\n",
        "        # Normalize English word (GloVe is lowercase)\n",
        "        eng_word = eng_word.lower()\n",
        "        \n",
        "        if egy_word in egy_vectors and eng_word in eng_vectors:\n",
        "            X.append(egy_vectors[egy_word])\n",
        "            Y.append(eng_vectors[eng_word])\n",
        "            valid_anchors.append((egy_word, eng_word))\n",
        "            \n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    \n",
        "    logger.info(f\"Valid Anchors: {len(X)} / {len(anchors)}\")\n",
        "    return X, Y, valid_anchors\n",
        "\n",
        "X, Y, valid_anchors = prepare_data(anchors, egy_vectors, eng_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Alignment\n",
        "\n",
        "Train a Ridge Regression model to map Egyptian vectors to English vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 6006, Test size: 1502\n",
            "Training Ridge Regression Alignment...\n",
            "R^2 Score on Train: 0.0884\n",
            "R^2 Score on Test: 0.0465\n"
          ]
        }
      ],
      "source": [
        "# Split Data\n",
        "X_train, X_test, Y_train, Y_test, anchors_train, anchors_test = train_test_split(\n",
        "    X, Y, valid_anchors, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "\n",
        "# Train Alignment\n",
        "print(\"Training Ridge Regression Alignment...\")\n",
        "aligner = Ridge(alpha=1.0)\n",
        "aligner.fit(X_train, Y_train)\n",
        "\n",
        "print(f\"R^2 Score on Train: {aligner.score(X_train, Y_train):.4f}\")\n",
        "print(f\"R^2 Score on Test: {aligner.score(X_test, Y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Accuracy\n",
        "\n",
        "Calculate Top-1, Top-5, and Top-10 accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on Test Set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1502/1502 [00:26<00:00, 55.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results (Test Set N=1502):\n",
            "Top-1 Accuracy: 28.16%\n",
            "Top-5 Accuracy: 36.09%\n",
            "Top-10 Accuracy: 40.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_accuracy(aligner, X_test, anchors_test, eng_vectors):\n",
        "    \"\"\"Evaluate accuracy by finding nearest neighbors in English space.\"\"\"\n",
        "    print(\"Evaluating on Test Set...\")\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    correct_top10 = 0\n",
        "    total = len(X_test)\n",
        "    \n",
        "    # Predict all test vectors\n",
        "    Y_pred = aligner.predict(X_test)\n",
        "    \n",
        "    for i in tqdm(range(total)):\n",
        "        pred_vec = Y_pred[i]\n",
        "        true_word = anchors_test[i][1]\n",
        "        \n",
        "        # Find nearest neighbors in GloVe\n",
        "        neighbors = eng_vectors.similar_by_vector(pred_vec, topn=10)\n",
        "        neighbor_words = [w for w, s in neighbors]\n",
        "        \n",
        "        if true_word == neighbor_words[0]:\n",
        "            correct_top1 += 1\n",
        "        if true_word in neighbor_words[:5]:\n",
        "            correct_top5 += 1\n",
        "        if true_word in neighbor_words[:10]:\n",
        "            correct_top10 += 1\n",
        "            \n",
        "    acc_top1 = correct_top1 / total * 100\n",
        "    acc_top5 = correct_top5 / total * 100\n",
        "    acc_top10 = correct_top10 / total * 100\n",
        "    \n",
        "    print(f\"\\nResults (Test Set N={total}):\")\n",
        "    print(f\"Top-1 Accuracy: {acc_top1:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {acc_top5:.2f}%\")\n",
        "    print(f\"Top-10 Accuracy: {acc_top10:.2f}%\")\n",
        "    \n",
        "    return acc_top1, acc_top5, acc_top10\n",
        "\n",
        "acc_top1, acc_top5, acc_top10 = evaluate_accuracy(aligner, X_test, anchors_test, eng_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-22 11:05:23,897 - INFO - Results saved to /Users/crashy/Development/heiroglyphy/heiro_v8_use_coptic/results.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"total_anchors\": 8579,\n",
            "  \"valid_anchors\": 7508,\n",
            "  \"top1_accuracy\": 28.1624500665779,\n",
            "  \"top5_accuracy\": 36.085219707057256,\n",
            "  \"top10_accuracy\": 40.279627163781626,\n",
            "  \"status\": \"success\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'total_anchors': len(anchors),\n",
        "    'valid_anchors': len(valid_anchors),\n",
        "    'top1_accuracy': acc_top1,\n",
        "    'top5_accuracy': acc_top5,\n",
        "    'top10_accuracy': acc_top10,\n",
        "    'status': 'success'\n",
        "}\n",
        "\n",
        "output_path = PROJECT_ROOT / 'results.json'\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "    \n",
        "logger.info(f\"Results saved to {output_path}\")\n",
        "print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "heiroglyphy",
      "language": "python",
      "name": "heiroglyphy"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
