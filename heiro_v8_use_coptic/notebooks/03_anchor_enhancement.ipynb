{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# V8 Anchor Enhancement: Egyptian → Coptic → English\n",
        "\n",
        "## Goal\n",
        "Combine Egyptian-Coptic cognates with Coptic-English Bible mappings to create enhanced Egyptian-English anchors.\n",
        "\n",
        "## Strategy\n",
        "1. Load Egyptian-Coptic cognates from ThotBank\n",
        "2. Load Coptic-English word pairs from OPUS Bible\n",
        "3. Chain mappings: Egyptian → Coptic → English\n",
        "4. Merge with V7 baseline anchors\n",
        "5. Analyze coverage improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/crashy/Development/heiroglyphy/heiro_v8_use_coptic\n",
            "Cognates file exists: True\n",
            "Coptic-English file exists: True\n",
            "V7 anchors file exists: True\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "PROCESSED_DIR = PROJECT_ROOT / 'data/processed'\n",
        "\n",
        "# Input files\n",
        "COGNATES_PATH = PROCESSED_DIR / 'egyptian_coptic_cognates.json'\n",
        "COPTIC_ENG_PATH = PROCESSED_DIR / 'coptic_english_word_pairs.json'\n",
        "\n",
        "# V7 baseline anchors\n",
        "V7_ANCHORS_PATH = PROJECT_ROOT.parent / 'heiro_v7_FastTextVisual/data/processed/anchors.json'\n",
        "\n",
        "print(f'Project root: {PROJECT_ROOT}')\n",
        "print(f'Cognates file exists: {COGNATES_PATH.exists()}')\n",
        "print(f'Coptic-English file exists: {COPTIC_ENG_PATH.exists()}')\n",
        "print(f'V7 anchors file exists: {V7_ANCHORS_PATH.exists()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2326 Egyptian-Coptic cognate pairs\n",
            "Sample: {'egyptian': 'bḏꜣ', 'egyptian_meaning': \"crucible, bread mold; mold, baker's oven, [a (measuring) vessel], [a copper jug], [a mold for making figures of Osiris]\", 'coptic': 'ⲃⲏⲧⲉ, ϩⲃⲏⲧⲉ', 'coptic_meaning': 'scale-like plate', 'entry_id': '0', 'coptic_id': 'C553'}\n"
          ]
        }
      ],
      "source": [
        "# Load Egyptian-Coptic cognates\n",
        "with open(COGNATES_PATH, 'r', encoding='utf-8') as f:\n",
        "    cognates = json.load(f)\n",
        "\n",
        "print(f'Loaded {len(cognates)} Egyptian-Coptic cognate pairs')\n",
        "print(f'Sample: {cognates[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5231 Coptic-English word pairs\n",
            "Sample: {'coptic': 'ⲟⲩⲟϩ', 'english': 'and', 'count': 6532}\n"
          ]
        }
      ],
      "source": [
        "# Load Coptic-English word pairs\n",
        "with open(COPTIC_ENG_PATH, 'r', encoding='utf-8') as f:\n",
        "    coptic_english = json.load(f)\n",
        "\n",
        "print(f'Loaded {len(coptic_english)} Coptic-English word pairs')\n",
        "print(f'Sample: {coptic_english[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 8541 V7 baseline anchors\n",
            "Sample: ('n', 'the')\n"
          ]
        }
      ],
      "source": [
        "# Load V7 baseline anchors\n",
        "with open(V7_ANCHORS_PATH, 'r', encoding='utf-8') as f:\n",
        "    v7_anchors_list = json.load(f)\n",
        "\n",
        "# Convert list to dictionary for easier lookup\n",
        "v7_anchors = {item['hieroglyphic']: item['english'] for item in v7_anchors_list}\n",
        "\n",
        "print(f'Loaded {len(v7_anchors)} V7 baseline anchors')\n",
        "print(f'Sample: {list(v7_anchors.items())[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Anchors from ThotBank\n",
        "\n",
        "Use ThotBank's Egyptian-English meanings directly (bypassing noisy Bible co-occurrence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ThotBank direct extraction results:\n",
            "  Total cognates: 2326\n",
            "  With English meanings: 2246\n",
            "  New anchors created: 809\n",
            "\n",
            "Sample new anchors:\n",
            "   1. bḏꜣ                       → crucible\n",
            "   2. bgs                       → to injure; to be injured; to be disloyal\n",
            "   3. bhꜣ                       → fan\n",
            "   4. bẖ                        → Buchis (sacred bull of Armant)\n",
            "   5. bḥz                       → calf\n",
            "   6. bj                        → bee\n",
            "   7. bjk                       → falcon\n",
            "   8. bjn                       → harp\n",
            "   9. bjꜣj                      → amazement; confusion\n",
            "  10. bkꜣ                       → to be (become) pregnant; to make pregnant\n",
            "  11. bny                       → sweet\n",
            "  12. bnw                       → to escape; to depart\n",
            "  13. bl                        → outside\n",
            "  14. bq                        → to be hostile\n",
            "  15. bꜣ                        → eyeball; eye\n",
            "  16. br                        → a mullet\n",
            "  17. brg                       → a semi-precious stone (beryl?)\n",
            "  18. brq                       → to sparkle (Sem. loan word)\n",
            "  19. bs                        → Bes\n",
            "  20. bš                        → malted grain? (for making beer)\n"
          ]
        }
      ],
      "source": [
        "# Extract anchors directly from ThotBank Egyptian meanings\n",
        "# ThotBank already has Egyptian words with English translations!\n",
        "new_anchors = {}\n",
        "match_stats = {\n",
        "    'total_cognates': len(cognates),\n",
        "    'with_english_meaning': 0,\n",
        "    'new_anchors_created': 0\n",
        "}\n",
        "\n",
        "for cognate in cognates:\n",
        "    egy_word = cognate['egyptian']\n",
        "    egy_meaning = cognate['egyptian_meaning']\n",
        "    \n",
        "    # Use ThotBank's English meaning directly\n",
        "    if egy_word and egy_meaning and egy_meaning.strip():\n",
        "        match_stats['with_english_meaning'] += 1\n",
        "        \n",
        "        # Clean up the meaning (take first word/phrase if multiple)\n",
        "        # Remove brackets and extra annotations\n",
        "        clean_meaning = egy_meaning.strip()\n",
        "        clean_meaning = clean_meaning.replace('[', '').replace(']', '')\n",
        "        \n",
        "        # Take first meaning if comma-separated\n",
        "        if ',' in clean_meaning:\n",
        "            clean_meaning = clean_meaning.split(',')[0].strip()\n",
        "        \n",
        "        # Only add if we have a clean meaning\n",
        "        if clean_meaning and len(clean_meaning) > 0:\n",
        "            if egy_word not in new_anchors:\n",
        "                new_anchors[egy_word] = clean_meaning\n",
        "                match_stats['new_anchors_created'] += 1\n",
        "\n",
        "print('ThotBank direct extraction results:')\n",
        "print(f\"  Total cognates: {match_stats['total_cognates']}\")\n",
        "print(f\"  With English meanings: {match_stats['with_english_meaning']}\")\n",
        "print(f\"  New anchors created: {match_stats['new_anchors_created']}\")\n",
        "print(f\"\\nSample new anchors:\")\n",
        "for i, (egy, eng) in enumerate(list(new_anchors.items())[:20]):\n",
        "    print(f\"  {i+1:2d}. {egy:25s} → {eng}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge with V7 Baseline Anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anchor enhancement results:\n",
            "  V7 baseline anchors: 8541\n",
            "  New anchors from Coptic bridge: 809\n",
            "  New additions (non-overlapping): 368\n",
            "  Total enhanced anchors: 8909\n",
            "  Improvement: +368 anchors (4.3%)\n"
          ]
        }
      ],
      "source": [
        "# Merge new anchors with V7 baseline\n",
        "# V7 anchors take precedence (they're from direct Egyptian-English dictionaries)\n",
        "enhanced_anchors = v7_anchors.copy()\n",
        "\n",
        "# Add new anchors that don't conflict\n",
        "new_additions = 0\n",
        "for egy_word, eng_word in new_anchors.items():\n",
        "    if egy_word not in enhanced_anchors:\n",
        "        enhanced_anchors[egy_word] = eng_word\n",
        "        new_additions += 1\n",
        "\n",
        "print('Anchor enhancement results:')\n",
        "print(f'  V7 baseline anchors: {len(v7_anchors)}')\n",
        "print(f'  New anchors from Coptic bridge: {len(new_anchors)}')\n",
        "print(f'  New additions (non-overlapping): {new_additions}')\n",
        "print(f'  Total enhanced anchors: {len(enhanced_anchors)}')\n",
        "print(f'  Improvement: +{new_additions} anchors ({100*new_additions/len(v7_anchors):.1f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coverage comparison:\n",
            "\n",
            "V7 Baseline:\n",
            "  Total anchors: 8541\n",
            "\n",
            "V8 Enhanced:\n",
            "  Total anchors: 8909\n",
            "  New anchors: 368\n",
            "  Coverage increase: 4.31%\n"
          ]
        }
      ],
      "source": [
        "# Compare anchor coverage\n",
        "print('Coverage comparison:')\n",
        "print(f'\\nV7 Baseline:')\n",
        "print(f'  Total anchors: {len(v7_anchors)}')\n",
        "\n",
        "print(f'\\nV8 Enhanced:')\n",
        "print(f'  Total anchors: {len(enhanced_anchors)}')\n",
        "print(f'  New anchors: {new_additions}')\n",
        "print(f'  Coverage increase: {100*new_additions/len(v7_anchors):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Enhanced Anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save enhanced anchors\n",
        "OUTPUT_PATH = PROCESSED_DIR / 'enhanced_anchors.json'\n",
        "\n",
        "with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
        "    json.dump(enhanced_anchors, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f'Saved {len(enhanced_anchors)} enhanced anchors to {OUTPUT_PATH}')\n",
        "\n",
        "# Also save the new anchors separately for analysis\n",
        "NEW_ANCHORS_PATH = PROCESSED_DIR / 'coptic_bridge_anchors.json'\n",
        "with open(NEW_ANCHORS_PATH, 'w', encoding='utf-8') as f:\n",
        "    json.dump(new_anchors, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f'Saved {len(new_anchors)} Coptic-bridge anchors to {NEW_ANCHORS_PATH}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Successfully created enhanced anchor dictionary using Coptic as a bridge language.\n",
        "\n",
        "**Key Results**:\n",
        "- Chained Egyptian → Coptic → English mappings\n",
        "- Added new anchors to V7 baseline\n",
        "- Improved anchor coverage\n",
        "\n",
        "**Next Steps**:\n",
        "1. Use enhanced anchors to retrain V7 alignment model\n",
        "2. Evaluate on test set\n",
        "3. Compare accuracy to V7 baseline (29.10%)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "heiroglyphy",
      "language": "python",
      "name": "heiroglyphy"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
